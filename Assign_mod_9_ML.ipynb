{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#THEORITICAL QUESTIONS"
      ],
      "metadata": {
        "id": "37bndaOJUDZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Can we use Bagging for regression problems?**"
      ],
      "metadata": {
        "id": "GviaVeoeUDOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Yes, Bagging (Bootstrap Aggregating) can be used for regression problems. Bagging involves training multiple instances of a base model (e.g., decision trees) on different subsets of the training data, created via bootstrap sampling (random sampling with replacement). For regression, the predictions from each model are aggregated, typically by averaging, to produce the final output. This approach, known as a Bagging Regressor, reduces variance and helps improve model stability and accuracy compared to a single regressor. For example, scikit-learn’s BaggingRegressor can be used with base estimators like decision trees to handle regression tasks."
      ],
      "metadata": {
        "id": "ouTbk2pdUC8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **What is the difference between multiple model training and single model training?**"
      ],
      "metadata": {
        "id": "S-WPZC6cUCya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* **Single Model Training:**  Involves training one model on the entire dataset to make predictions. For example, a single decision tree or linear regression model is trained to minimize a loss function. It is simpler and faster but can suffer from high variance (overfitting) or bias (underfitting) depending on the model’s complexity.\n",
        "\n",
        "* **Multiple Model Training:** Involves training multiple models, either independently or sequentially, to combine their predictions. This is common in ensemble methods like Bagging, Boosting, or Stacking. Multiple models reduce variance (e.g., Bagging) or bias (e.g., Boosting) by leveraging diversity among models. It is computationally more expensive but often yields better performance due to the aggregation of predictions."
      ],
      "metadata": {
        "id": "TZjiasa3UCoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Explain the concept of feature randomness in Random Forest.**"
      ],
      "metadata": {
        "id": "ivwzYt0ZUCfH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Feature randomness in Random Forest refers to the process of selecting a random subset of features (predictors) at each split when constructing a decision tree. Unlike a standard decision tree, which considers all features to find the best split, Random Forest limits the number of features considered at each node (e.g., max_features in scikit-learn, often set to sqrt(n_features) or log2(n_features)). This randomness:\n",
        "\n",
        "* Increases diversity among trees, reducing correlation between them.\n",
        "* Prevents overfitting by ensuring no single feature dominates all trees.\n",
        "* Improves generalization by exploring a wider range of feature combinations."
      ],
      "metadata": {
        "id": "qH-yIRcJUCWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **What is OOB (Out-of-Bag) Score?**"
      ],
      "metadata": {
        "id": "DnZ7r6_fUCMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The Out-of-Bag (OOB) Score is a performance metric used in Bagging and Random Forest models. In Bagging, each base model is trained on a bootstrap sample (a random subset of the data with replacement). On average, about 37% of the data (the \"out-of-bag\" samples) are not used in training any given model. These OOB samples act as a validation set. The OOB Score is computed by:\n",
        "\n",
        "* Predicting the output for each OOB sample using only the trees that did not include it in their training set.\n",
        "* Aggregating predictions (e.g., majority vote for classification, average for regression).\n",
        "* Comparing predictions to actual labels to calculate accuracy (classification) or error (regression). The OOB Score is a convenient, unbiased estimate of model performance without needing a separate validation set."
      ],
      "metadata": {
        "id": "NctDawTuUCDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **How can you measure the importance of features in a Random Forest model?**"
      ],
      "metadata": {
        "id": "FooFZHfMUB57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Feature importance in Random Forest is typically measured using one of these methods:\n",
        "\n",
        "* **Mean Decrease in Impurity (MDI):** Each feature’s importance is calculated based on the total reduction in the impurity (e.g., Gini impurity for classification, variance for regression) it contributes across all splits in all trees. Features that reduce impurity more are considered more important.\n",
        "\n",
        "* **Mean Decrease in Accuracy (Permutation Importance):** The importance of a feature is assessed by shuffling its values and measuring the decrease in model accuracy on OOB samples or a validation set. A larger drop in accuracy indicates higher importance.\n",
        "\n",
        "* **Implementation:** In scikit-learn, feature_importances_ provides MDI-based scores, normalized to sum to 1. Permutation importance is available via sklearn.inspection.permutation_importance."
      ],
      "metadata": {
        "id": "p5oVmAh3UBwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Explain the working principle of a Bagging Classifier.**"
      ],
      "metadata": {
        "id": "4yeABgKTUBn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "A Bagging Classifier works by:\n",
        "\n",
        "1. **Bootstrap Sampling:** Generate multiple (e.g., n_estimators) bootstrap samples from the training data by sampling with replacement. Each sample is the same size as the original dataset but may contain duplicates or omit some data points.\n",
        "\n",
        "2. **Base Model Training:** Train a base classifier (e.g., decision tree) independently on each bootstrap sample. Each classifier learns slightly different patterns due to the variation in samples.\n",
        "\n",
        "3. **Prediction Aggregation:** For a new input, each classifier makes a prediction, and the final output is determined by majority voting (for classification). This reduces variance by averaging out errors from individual models.\n",
        "\n",
        "4. **Advantages:** Bagging reduces overfitting, especially for high-variance models like decision trees, by creating diverse models that collectively produce a more stable prediction."
      ],
      "metadata": {
        "id": "DSOl_vbzUBem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How do you evaluate a Bagging Classifier’s performance?"
      ],
      "metadata": {
        "id": "4kANBM9YUBTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "A Bagging Classifier’s performance can be evaluated using:\n",
        "\n",
        "* Accuracy: The proportion of correct predictions on a test set.\n",
        "Confusion Matrix: To analyze true positives, false positives, true negatives, and false negatives.\n",
        "\n",
        "* Precision, Recall, F1-Score: For imbalanced datasets, these metrics provide insights into performance on specific classes.\n",
        "\n",
        "* ROC-AUC Score: Measures the trade-off between true positive rate and false positive rate, suitable for binary classification.\n",
        "\n",
        "* Cross-Validation: Use k-fold cross-validation to assess generalization by splitting data into k subsets and training/testing multiple times.\n",
        "OOB Score: If available, use the OOB score as an internal validation metric without needing a separate test set."
      ],
      "metadata": {
        "id": "ln8lPtB2UBKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. How does a Bagging Regressor work?"
      ],
      "metadata": {
        "id": "2BXO__zJUBAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "A Bagging Regressor works similarly to a Bagging Classifier but for regression tasks:\n",
        "\n",
        "1. Bootstrap Sampling: Generate multiple bootstrap samples from the training data.\n",
        "\n",
        "2. Base Model Training: Train a base regressor (e.g., decision tree) on each bootstrap sample.\n",
        "\n",
        "3. Prediction Aggregation: For a new input, each regressor predicts a continuous value, and the final prediction is the average (or weighted average) of all predictions.\n",
        "\n",
        "4. Purpose: Reduces variance and improves robustness by averaging predictions, making it effective for noisy or complex datasets."
      ],
      "metadata": {
        "id": "EP4PSDHdUA31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is the main advantage of ensemble techniques?"
      ],
      "metadata": {
        "id": "C2HSEkT7UAu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The main advantage of ensemble techniques is improved predictive performance by combining multiple models to reduce errors. Specifically:\n",
        "\n",
        "* Reduced Variance: Bagging and Random Forest reduce overfitting by averaging predictions from diverse models.\n",
        "\n",
        "* Reduced Bias: Boosting focuses on correcting errors of weak learners, improving overall accuracy.\n",
        "\n",
        "* Robustness: Ensembles are less sensitive to noise and outliers due to aggregation.\n",
        "\n",
        "* Versatility: Applicable to both classification and regression tasks across various domains."
      ],
      "metadata": {
        "id": "bfP2YL05UAl6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What is the main challenge of ensemble methods?"
      ],
      "metadata": {
        "id": "4E-MlfSUUAdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The main challenge of ensemble methods is:\n",
        "\n",
        "* Computational Complexity: Training multiple models increases computational cost and memory usage, making ensembles slower and more resource-intensive than single models.\n",
        "\n",
        "* Interpretability: Ensembles, especially Random Forest or Boosting, are less interpretable than single models like decision trees or linear regression.\n",
        "\n",
        "* Tuning Complexity: Ensembles have multiple hyperparameters (e.g., number of estimators, learning rate) that require careful tuning.\n",
        "\n",
        "* Risk of Overfitting: If not properly regularized (e.g., too many trees or improper boosting), ensembles can overfit, especially on small datasets."
      ],
      "metadata": {
        "id": "m8CAPpYKUATr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Explain the key idea behind ensemble techniques."
      ],
      "metadata": {
        "id": "D67UDH1RUAKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The key idea behind ensemble techniques is to combine predictions from multiple models to achieve better performance than any single model. By leveraging diversity among models (e.g., through different training data subsets, feature subsets, or algorithms), ensembles reduce errors from bias, variance, or noise. Common approaches include:\n",
        "\n",
        "* Bagging: Reduces variance by averaging predictions from models trained on different data subsets.\n",
        "\n",
        "* Boosting: Reduces bias by sequentially training models to focus on errors of previous models.\n",
        "\n",
        "* Stacking: Combines predictions from different model types using a meta-learner."
      ],
      "metadata": {
        "id": "p2fPVOczUAA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is a Random Forest Classifier?"
      ],
      "metadata": {
        "id": "f95opwvGT_ot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "A Random Forest Classifier is an ensemble method that combines multiple decision trees to perform classification tasks. It works by:\n",
        "\n",
        "1. Creating bootstrap samples of the training data.\n",
        "\n",
        "2. Training a decision tree on each sample, with feature randomness (random subset of features at each split).\n",
        "\n",
        "3. Aggregating predictions via majority voting to determine the final class. It improves upon single decision trees by reducing overfitting, handling high-dimensional data, and providing robust predictions. Scikit-learn’s RandomForestClassifier is a common implementation."
      ],
      "metadata": {
        "id": "cAlETJ4sT_em"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What are the main types of ensemble techniques?"
      ],
      "metadata": {
        "id": "BgE3IY6UT_VN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The main types of ensemble techniques are:\n",
        "\n",
        "* Bagging (Bootstrap Aggregating): Trains multiple models on bootstrap samples and aggregates predictions (e.g., Random Forest).\n",
        "\n",
        "* Boosting: Sequentially trains models, with each model focusing on correcting errors of the previous ones (e.g., AdaBoost, Gradient Boosting, XGBoost).\n",
        "\n",
        "* Stacking: Trains multiple diverse models and uses a meta-learner (e.g., logistic regression) to combine their predictions.\n",
        "\n",
        "* Voting: Combines predictions from different model types using majority voting (classification) or averaging (regression)."
      ],
      "metadata": {
        "id": "nPPFmMWST_L3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What is ensemble learning in machine learning?"
      ],
      "metadata": {
        "id": "baRjIPfVT_Bo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Ensemble learning is a machine learning paradigm where multiple models (base learners) are trained and combined to solve a predictive task. The goal is to improve accuracy, robustness, and generalization by leveraging the strengths of individual models. Ensemble methods work by:\n",
        "\n",
        "* Reducing variance (e.g., Bagging).\n",
        "* Reducing bias (e.g., Boosting).\n",
        "* Combining diverse models (e.g., Stacking). Examples include Random Forest, Gradient Boosting, and AdaBoost."
      ],
      "metadata": {
        "id": "ktHklyH4T-4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. When should we avoid using ensemble methods?"
      ],
      "metadata": {
        "id": "PvKltHR5T-uX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Ensemble methods should be avoided when:\n",
        "\n",
        "* Computational Resources Are Limited: Ensembles are resource-intensive, making them impractical for real-time or resource-constrained applications.\n",
        "\n",
        "* Interpretability Is Critical: Ensembles are harder to interpret than single models like linear regression or decision trees.\n",
        "\n",
        "* Small Datasets: With limited data, ensembles may overfit or fail to provide significant improvements over simpler models.\n",
        "\n",
        "* Simple Problems: For linearly separable or low-complexity problems, simpler models may perform just as well with less complexity.\n",
        "\n",
        "* Time Constraints: Training and tuning ensembles can be time-consuming."
      ],
      "metadata": {
        "id": "D7_u6sr_T-kp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. How does Bagging help in reducing overfitting?"
      ],
      "metadata": {
        "id": "Y8u8d9p8T-ao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Bagging reduces overfitting by:\n",
        "\n",
        "* Reducing Variance: Training multiple models on different bootstrap samples creates diversity, so errors from individual models (e.g., overfitting in decision trees) are averaged out during aggregation.\n",
        "\n",
        "* Stabilizing Predictions: By combining predictions (e.g., majority voting or averaging), Bagging smooths out erratic predictions from high-variance models.\n",
        "\n",
        "* Robustness to Noise: Bootstrap sampling ensures models are exposed to varied data subsets, making them less sensitive to outliers or noise in the training data."
      ],
      "metadata": {
        "id": "My3lqSi8T-RB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Why is Random Forest better than a single Decision Tree?"
      ],
      "metadata": {
        "id": "rBGIrOg4T-Hb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Random Forest is better than a single Decision Tree because:\n",
        "\n",
        "* Lower Variance: Random Forest averages predictions from multiple trees, reducing overfitting compared to a single tree, which can fit noise in the data.\n",
        "\n",
        "* Feature Randomness: By selecting random subsets of features at each split, Random Forest ensures diversity among trees, improving generalization.\n",
        "\n",
        "* Robustness: It handles noisy data and outliers better due to aggregation.\n",
        "\n",
        "* Feature Importance: Random Forest provides insights into feature importance, unlike a single tree.\n",
        "\n",
        "* Scalability: It performs well on high-dimensional and large datasets."
      ],
      "metadata": {
        "id": "E5lm_OCBT99i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What is the role of bootstrap sampling in Bagging?"
      ],
      "metadata": {
        "id": "6kZQb5t3T90e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Bootstrap sampling is the core mechanism of Bagging. It involves:\n",
        "\n",
        "* Randomly selecting subsets of the training data with replacement, where each subset is the same size as the original dataset.\n",
        "\n",
        "* Training each base model on a different bootstrap sample, creating diversity among models.\n",
        "\n",
        "* Enabling OOB evaluation, as some data points are left out of each sample. This process reduces variance by ensuring models learn different aspects of the data, and aggregation (e.g., voting or averaging) produces a more stable and accurate prediction."
      ],
      "metadata": {
        "id": "_PXVqXuKT9s1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What are some real-world applications of ensemble techniques?\n"
      ],
      "metadata": {
        "id": "Kh9N0rjET71h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Real-world applications of ensemble techniques include:\n",
        "\n",
        "* Finance: Credit risk assessment, fraud detection (e.g., Random Forest for anomaly detection).\n",
        "\n",
        "* Healthcare: Disease diagnosis (e.g., Random Forest on medical imaging or patient data).\n",
        "\n",
        "* Marketing: Customer segmentation, churn prediction (e.g., Gradient Boosting for predicting customer behavior).\n",
        "\n",
        "* Natural Language Processing: Sentiment analysis, text classification (e.g., ensemble of classifiers).\n",
        "\n",
        "* Image Recognition: Object detection, facial recognition (e.g., Stacking for combining CNNs).\n",
        "\n",
        "* Weather Forecasting: Predicting rainfall or temperature (e.g., Bagging Regressor for time-series data)."
      ],
      "metadata": {
        "id": "AK09zBWdTzAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What is the difference between Bagging and Boosting?"
      ],
      "metadata": {
        "id": "yrTrhLjVTyoL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Bagging:**\n",
        "* Trains multiple models independently on bootstrap samples.\n",
        "* Aggregates predictions via majority voting (classification) or averaging (regression).\n",
        "* Reduces variance, suitable for high-variance models like decision trees.\n",
        "* Example: Random Forest.\n",
        "* Parallelizable, as models are trained independently.\n",
        "\n",
        "**Boosting:**\n",
        "* Trains models sequentially, with each model focusing on correcting errors of the previous ones by assigning higher weights to misclassified samples.\n",
        "* Aggregates predictions using weighted voting or averaging.\n",
        "* Reduces bias, suitable for weak learners (e.g., shallow trees).\n",
        "* Example: AdaBoost, Gradient Boosting, XGBoost.\n",
        "* Not parallelizable, as models depend on previous ones."
      ],
      "metadata": {
        "id": "g9qdj97RTyct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PRACTICAL QUESTIONS\n"
      ],
      "metadata": {
        "id": "nrXuV8BZTyEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy."
      ],
      "metadata": {
        "id": "d4jIkSTUeeVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_wine(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=22)\n",
        "\n",
        "bag = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=22)\n",
        "bag.fit(X_train, y_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, bag.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hXfKGPSeeA5",
        "outputId": "e20481ae-1fca-4604-da31-99f873f8e591"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)."
      ],
      "metadata": {
        "id": "i4GKBCwdedu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "br = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=20, random_state=0)\n",
        "br.fit(X_train, y_train)\n",
        "print(\"MSE:\", mean_squared_error(y_test, br.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qeDGfTOeddh",
        "outputId": "78ebffe1-4a05-4d49-903a-8e8e9f9af1ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.2859019408131398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores."
      ],
      "metadata": {
        "id": "AQTqEKQ3edLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "importances = rf.feature_importances_\n",
        "print(importances)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocFZaCLMec3u",
        "outputId": "3ba0d59d-cf60-4a76-f91d-3019a5ab10c5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.03971058 0.01460399 0.05314639 0.04277978 0.00816485 0.01140166\n",
            " 0.08321459 0.0902992  0.00443533 0.00443395 0.01951684 0.00459978\n",
            " 0.00868228 0.04355077 0.00464415 0.0036549  0.00701442 0.00504716\n",
            " 0.00371411 0.00658253 0.08127686 0.01649014 0.07138828 0.12319232\n",
            " 0.01033481 0.01580059 0.03174022 0.17229521 0.01310266 0.00518165]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "24. Train a Random Forest Regressor and compare its performance with a single Decision Tree."
      ],
      "metadata": {
        "id": "bJbXZwMUeclz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "dt = DecisionTreeRegressor(random_state=0).fit(X_train, y_train)\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=0).fit(X_train, y_train)\n",
        "\n",
        "print(\"DT MSE:\", mean_squared_error(y_test, dt.predict(X_test)))\n",
        "print(\"RF MSE:\", mean_squared_error(y_test, rf.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA8bHjWQecRj",
        "outputId": "2d263510-c283-46c4-abdb-e192d4c02792"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DT MSE: 0.5501739317092635\n",
            "RF MSE: 0.27207938818489935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier."
      ],
      "metadata": {
        "id": "sUZf1j1Veb-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.ensemble import RandomForestRegressor # Changed to Regressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error # Added for evaluation\n",
        "\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "rf_oob = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=42)\n",
        "rf_oob.fit(X_train, y_train)\n",
        "print(\"OOB Score:\", rf_oob.oob_score_)\n",
        "\n",
        "# Optional: Evaluate on the test set as well\n",
        "# print(\"Test MSE:\", mean_squared_error(y_test, rf_oob.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFOy4iYzebsl",
        "outputId": "1fbc54c9-2d59-4596-d600-0812de2eabea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB Score: 0.8035286949244751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "26. Train a Bagging Classifier using SVM as a base estimator and print accuracy."
      ],
      "metadata": {
        "id": "3V0dKiAcebZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer # Added import for breast cancer dataset\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True) # Loaded breast cancer dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) # Split data\n",
        "\n",
        "bag_svm = BaggingClassifier(estimator=SVC(), n_estimators=10, random_state=0)\n",
        "bag_svm.fit(X_train, y_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, bag_svm.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xVgVsn_ebGC",
        "outputId": "aa277c2f-0384-4f5c-f37b-0ec50fae477f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9440559440559441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Train a Random Forest Classifier with different numbers of trees and compare accuracy."
      ],
      "metadata": {
        "id": "etidgOkoeaxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for n in [10, 50, 100, 200]:\n",
        "    rf = RandomForestClassifier(n_estimators=n, random_state=0)\n",
        "    rf.fit(X_train, y_train)\n",
        "    print(f\"{n} trees → Accuracy:\", accuracy_score(y_test, rf.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4p9QFlUeacq",
        "outputId": "c53fa366-f1c0-431c-8e5a-0e88efb0ac31"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 trees → Accuracy: 0.951048951048951\n",
            "50 trees → Accuracy: 0.965034965034965\n",
            "100 trees → Accuracy: 0.972027972027972\n",
            "200 trees → Accuracy: 0.972027972027972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score."
      ],
      "metadata": {
        "id": "cYc8ioi_eWqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Generate a synthetic binary classification dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression as base estimator\n",
        "base_estimator = LogisticRegression(random_state=42)\n",
        "\n",
        "# Initialize Bagging Classifier\n",
        "bagging_clf = BaggingClassifier(estimator=base_estimator,\n",
        "                               n_estimators=10,\n",
        "                               random_state=42)\n",
        "\n",
        "# Train the model\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for AUC calculation\n",
        "y_pred_proba = bagging_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate AUC score\n",
        "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(f\"AUC Score: {auc_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt4_0T6UeWZV",
        "outputId": "1db4aaa0-2f82-4a62-9ea6-19c822b860d5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Score: 0.9225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "29. Train a Random Forest Regressor and analyze feature importance scores."
      ],
      "metadata": {
        "id": "fhiH0JUMeWEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=0)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "print(\"Feature importances:\", rf_reg.feature_importances_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmOKB_PdeVgE",
        "outputId": "351038b7-d559-40ee-ed15-1748e21d0bf9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature importances: [0.00806702 0.01325913 0.01298161 0.01225561 0.00908718 0.62168603\n",
            " 0.0153898  0.01252494 0.01398847 0.01194213 0.00943164 0.0220119\n",
            " 0.0148552  0.01277904 0.12969391 0.01520658 0.01518339 0.01360912\n",
            " 0.02271488 0.01333243]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "30. Train an ensemble model using both Bagging and Random Forest and compare accuracy."
      ],
      "metadata": {
        "id": "iGIJV8t6eXe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer # Added import for breast cancer dataset\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True) # Loaded breast cancer dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) # Split data\n",
        "\n",
        "\n",
        "bag = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=0)\n",
        "bag.fit(X_train, y_train)\n",
        "acc_bag = accuracy_score(y_test, bag.predict(X_test))\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "rf.fit(X_train, y_train)\n",
        "acc_rf = accuracy_score(y_test, rf.predict(X_test))\n",
        "\n",
        "print(\"Bagging Acc:\", acc_bag)\n",
        "print(\"Random Forest Acc:\", acc_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4FcBDJ7eVar",
        "outputId": "39f974e5-1dd0-4616-9d20-e1b0b2f98f0b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Acc: 0.9440559440559441\n",
            "Random Forest Acc: 0.972027972027972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV."
      ],
      "metadata": {
        "id": "k94kU4naeVKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_wine(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "param_grid = {\n",
        "  'n_estimators':[50,100],\n",
        "  'max_depth':[None,10],\n",
        "  'min_samples_split':[2,5]\n",
        "}\n",
        "grid = GridSearchCV(RandomForestClassifier(random_state=0),\n",
        "                    param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "print(\"Test accuracy:\", accuracy_score(y_test, grid.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiHZ5HhkeU3v",
        "outputId": "05516dd4-f960-4833-84e0-163a77855800"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
            "Test accuracy: 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "32. Train a Bagging Regressor with different numbers of base estimators and compare performance."
      ],
      "metadata": {
        "id": "FNMY4jaleUkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import fetch_california_housing # Changed to fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, y = fetch_california_housing(return_X_y=True) # Changed to fetch_california_housing\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, random_state=0)\n",
        "for n in [5,10,20,50]:\n",
        "    br = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=n, random_state=0) # Changed base_estimator to estimator\n",
        "    br.fit(X_train,y_train)\n",
        "    print(n, \"estimators → MSE:\", mean_squared_error(y_test, br.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9ezyvFCeUTB",
        "outputId": "2c3952a5-7a68-4b34-dbb3-9eb41b8fa3ca"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 estimators → MSE: 0.32236267968842397\n",
            "10 estimators → MSE: 0.29663228165878797\n",
            "20 estimators → MSE: 0.2859019408131398\n",
            "50 estimators → MSE: 0.27600734442616565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "33. Train a Random Forest Classifier and analyze misclassified samples."
      ],
      "metadata": {
        "id": "h0bedyLPeUB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X,y = load_breast_cancer(return_X_y=True)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y, random_state=0)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "mis = np.where(y_test != y_pred)[0]\n",
        "print(\"Misclassified indices:\", mis)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JejtWYQYeTxQ",
        "outputId": "229735aa-54d3-4219-a031-0e0f2722965d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96        53\n",
            "           1       0.99      0.97      0.98        90\n",
            "\n",
            "    accuracy                           0.97       143\n",
            "   macro avg       0.97      0.97      0.97       143\n",
            "weighted avg       0.97      0.97      0.97       143\n",
            "\n",
            "Misclassified indices: [10 13 14 73]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier."
      ],
      "metadata": {
        "id": "KqoCyvwveTgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
        "bag = BaggingClassifier(DecisionTreeClassifier(), n_estimators=10, random_state=0).fit(X_train, y_train)\n",
        "print(\"Decision tree acc:\", accuracy_score(y_test, dt.predict(X_test)))\n",
        "print(\"Bagging acc:\", accuracy_score(y_test, bag.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En2cLdmieTPJ",
        "outputId": "1615435c-91af-4d46-dadd-d64192eb9ba2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision tree acc: 0.8811188811188811\n",
            "Bagging acc: 0.972027972027972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "35. Train a Random Forest Classifier and visualize the confusion matrix."
      ],
      "metadata": {
        "id": "qlpvfC3NeS84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=0).fit(X_train, y_train)\n",
        "disp = ConfusionMatrixDisplay.from_estimator(rf, X_test, y_test, cmap='Blues')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "C4UzyBEueSj_",
        "outputId": "06d81f6e-8086-459c-f915-c8543fc60fa9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy."
      ],
      "metadata": {
        "id": "JHnosiEUTx0L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy7Uv2GgTiZF",
        "outputId": "c9cc9e34-a0ae-4ee3-d852-67ae60fd38a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking accuracy: 0.9300699300699301\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "estimators = [\n",
        "   ('dt', DecisionTreeClassifier()),\n",
        "   ('svm', SVC(probability=True)),\n",
        "]\n",
        "stack = StackingClassifier(estimators=estimators,\n",
        "                           final_estimator=LogisticRegression(),\n",
        "                           cv=5)\n",
        "stack.fit(X_train, y_train)\n",
        "print(\"Stacking accuracy:\", stack.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "37. Train a Random Forest Classifier and print the top 5 most important features."
      ],
      "metadata": {
        "id": "lsnTrgXrhcWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=0).fit(X_train, y_train)\n",
        "importances = rf.feature_importances_\n",
        "idx = np.argsort(importances)[::-1][:5]\n",
        "print(\"Top 5 feature indices:\", idx, \"importances:\", importances[idx])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YPx_is1hcEj",
        "outputId": "eeb9d6a4-4f8e-4999-972d-d9173c8576af"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 feature indices: [22 27 20  7 23] importances: [0.16027724 0.11711756 0.11657269 0.10305394 0.0634688 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and FI-score."
      ],
      "metadata": {
        "id": "_Bn47b7vhbzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "bag = BaggingClassifier(DecisionTreeClassifier(), n_estimators=10, random_state=0).fit(X_train, y_train)\n",
        "y_pred = bag.predict(X_test)\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
        "print(\"F1‑score:\", f1_score(y_test, y_pred, average='weighted'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBskhuy0hbie",
        "outputId": "2b38cb70-7fd1-4eac-de27-afcc97790853"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9726319135410045\n",
            "Recall: 0.972027972027972\n",
            "F1‑score: 0.9721298260624104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "39. Train a Random Forest Classifier and analyze the effect of max depth on accuracy."
      ],
      "metadata": {
        "id": "hdL7Nqr8hbP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for d in [None,5,10,20]:\n",
        "    rf = RandomForestClassifier(n_estimators=100, max_depth=d, random_state=0).fit(X_train, y_train)\n",
        "    print(f\"max_depth={d} → acc:\", rf.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ik9Y7IR4ha-m",
        "outputId": "67bb7cf9-4d00-4094-a6f8-dd31a026a16e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_depth=None → acc: 0.972027972027972\n",
            "max_depth=5 → acc: 0.972027972027972\n",
            "max_depth=10 → acc: 0.972027972027972\n",
            "max_depth=20 → acc: 0.972027972027972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance."
      ],
      "metadata": {
        "id": "VgglvkCChat6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor # Added import for DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "for base in [DecisionTreeRegressor(), KNeighborsRegressor()]:\n",
        "    br = BaggingRegressor(estimator=base, n_estimators=20, random_state=0).fit(X_train, y_train)\n",
        "    print(base.__class__.__name__, \"MSE:\", mean_squared_error(y_test, br.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsvgBmj9hadB",
        "outputId": "4f0c01ff-4feb-496a-b1c8-1ee06c36145a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeRegressor MSE: 0.029405594405594405\n",
            "KNeighborsRegressor MSE: 0.05041258741258741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score."
      ],
      "metadata": {
        "id": "E9hpJk2phaMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=0).fit(X_train, y_train)\n",
        "probs = rf.predict_proba(X_test)\n",
        "print(\"ROC‑AUC:\", roc_auc_score(y_test, probs[:,1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOFOgbsFhZ7u",
        "outputId": "8ecf8e1e-6c80-4ccd-e60a-204213e91d8c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC‑AUC: 0.9975890985324948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "42. Train a Bagging Classifier and evaluate its performance using cross-validation"
      ],
      "metadata": {
        "id": "OZhpYn4hhZrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "bag = BaggingClassifier(DecisionTreeClassifier(), n_estimators=10, random_state=0)\n",
        "scores = cross_val_score(bag, X, y, cv=5, scoring='accuracy')\n",
        "print(\"CV accuracies:\", scores, \"mean:\", scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqsR4G9OhZZ3",
        "outputId": "6f37185e-82ba-493d-bc07-6b3a1294317b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV accuracies: [0.93859649 0.92982456 0.98245614 0.97368421 0.96460177] mean: 0.9578326346840553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "43. Train a Random Forest Classifier and plot the Precision-Recall curve"
      ],
      "metadata": {
        "id": "KafJhsfPhZI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import PrecisionRecallDisplay\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=0).fit(X_train, y_train)\n",
        "probs = rf.predict_proba(X_test)[:,1]\n",
        "PrecisionRecallDisplay.from_predictions(y_test, probs)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "0MSo-M3nhY2V",
        "outputId": "b61c9f04-fdc5-438f-edc4-5f6e3afb541d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy."
      ],
      "metadata": {
        "id": "Nc-15T-OhYQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = [\n",
        "   ('rf', RandomForestClassifier(n_estimators=100, random_state=0)),\n",
        "]\n",
        "stack = StackingClassifier(estimators=estimators,\n",
        "                           final_estimator=LogisticRegression(),\n",
        "                           cv=5)\n",
        "stack.fit(X_train, y_train)\n",
        "print(\"Stacking (RF+LR) acc:\", stack.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyD3HFBxhX_u",
        "outputId": "cac7af76-5cf0-4641-8ebb-e68b56ccd99b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking (RF+LR) acc: 0.965034965034965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance."
      ],
      "metadata": {
        "id": "0PNz4uwEhXt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for frac in [0.5, 0.75, 1.0]:\n",
        "    br = BaggingRegressor(DecisionTreeRegressor(), n_estimators=20,\n",
        "                          max_samples=frac, random_state=0).fit(X_train, y_train)\n",
        "    print(f\"max_samples={frac} → MSE:\", mean_squared_error(y_test, br.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYrl7HaZhXWO",
        "outputId": "4d10e553-223c-44dc-cd8e-97d5fb1b7dfa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_samples=0.5 → MSE: 0.03520979020979021\n",
            "max_samples=0.75 → MSE: 0.0268006993006993\n",
            "max_samples=1.0 → MSE: 0.029405594405594405\n"
          ]
        }
      ]
    }
  ]
}